# éœ€è¦å¯¼å…¥æ–°çš„ Memory å’Œ Message ç±»
from core.memory import Memory
from core.message import UserMessage, SystemMessage, ToolMessage,LLMMessage
from engine.tool import function_to_schema ,ToolRegistry
from openai.types.chat import ChatCompletionMessageFunctionToolCall
from openai.types.chat import ChatCompletionMessageToolCall
from typing import List
import json
from rich import print as rprint
# ... å…¶ä»–åŽŸæœ‰å¯¼å…¥


class Agent:
    def __init__(self, llm, system_prompt: str = "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„ AI åŠ©æ‰‹ã€‚"):
        self.llm = llm
        #åˆå§‹åŒ–å·¥å…·æ¨¡å—
        self.toolregistry = ToolRegistry()
        # åˆå§‹åŒ–è®°å¿†æ¨¡å—
        self.memory = Memory(
            system_message=SystemMessage(content = system_prompt),
            max_messages=15 # è®¾å®šä¸€ä¸ªåˆç†çš„çª—å£å€¼
        )

    
    
    # _execute_tool æ–¹æ³•ä¿æŒä¸å˜...
    def _execute_tool(self,tool_call:ChatCompletionMessageFunctionToolCall)->dict:
        fun = self.toolregistry.get_tool(tool_call.function.name)
        func_args = json.loads(tool_call.function.arguments)
        result = fun(**func_args)
        #print("result=" + str(result))
        tool_result = dict()
        tool_result["tool_call_id"] = tool_call.id
        tool_result["content"] = str(result)
        tool_result["role"] = "tool"
        tool_result["name"] = tool_call.function.name
        return  tool_result


    def run(self, prompt: str, max_turns: int = 5):
        # 1. å°†ç”¨æˆ·è¾“å…¥å­˜å…¥è®°å¿†
        self.memory.add(UserMessage(content = prompt))
        current_turn = 0
        while current_turn < max_turns:
            current_turn += 1

            messages_to_send = self.memory.to_messages()
            rprint( messages_to_send)
            response_message = self.llm.chat(messages_to_send, self.toolregistry.tool_schemas)

            #å­˜LLMMessage åˆ°memory


            # 5. åˆ¤æ–­æ˜¯å¦è°ƒç”¨å·¥å…·
            if response_message.tool_calls:
                message = LLMMessage(content = response_message.content,
                tool_calls=LLMMessage.To_ToolCalls(response_message.tool_calls))
                self.memory.add(message)
                #self.memory.add(temp)
                for tool_call in response_message.tool_calls:
                    # æ‰§è¡Œå·¥å…·
                    tool_result_dict = self._execute_tool(tool_call)
                    #print("tool_result_dict:")
                    #print(tool_result_dict)
                    # å°è£…ä¸º ToolMessage å¯¹è±¡
                    tool_msg = ToolMessage(
                        content=tool_result_dict["content"],
                        tool_call_id=tool_result_dict["tool_call_id"]
                    )
                    #print("tool_msg:" + str(tool_msg))
                    
                    # å°†å·¥å…·ç»“æžœå­˜å…¥è®°å¿†
                    self.memory.add(tool_msg)
                
                # å¾ªçŽ¯ç»§ç»­ï¼Œä¸‹ä¸€è½® LLM ä¼šçœ‹åˆ°å·¥å…·ç»“æžœ
            else:
                message = LLMMessage(content = response_message.content)
                self.memory.add(message)
                print(f"ðŸ¤– Answer: {response_message.content}")
                return response_message.content
        
        return "Max turns reached."