# éœ€è¦å¯¼å…¥æ–°çš„ Memory å’Œ Message ç±»
from core.memory import Memory
from core.message import UserMessage, SystemMessage, ToolMessage,LLMMessage
from engine.tool import function_to_schema ,ToolRegistry
from openai.types.chat import ChatCompletionMessageFunctionToolCall
from openai.types.chat import ChatCompletionMessageToolCall
import json
# ... å…¶ä»–åŽŸæœ‰å¯¼å…¥

'''
agent ç±»çš„ç»„æˆ
ä½¿ç”¨çš„LLMæ¨¡åž‹ï¼š
å…¨éƒ¨çš„å·¥å…·å‡½æ•°ï¼š
memoryæ¨¡å—ï¼š



'''
class Agent:
    def __init__(self, llm, system_prompt: str = "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„ AI åŠ©æ‰‹ã€‚"):
        self.llm = llm
        #åˆå§‹åŒ–å·¥å…·æ¨¡å—
        self.toolregistry = ToolRegistry()
        # åˆå§‹åŒ–è®°å¿†æ¨¡å—
        self.memory = Memory(
            system_message=SystemMessage(system_prompt),
            max_messages=15 # è®¾å®šä¸€ä¸ªåˆç†çš„çª—å£å€¼
        )

        #

    # # tool è£…é¥°å™¨ä¿æŒä¸å˜...
    # def tool(self,func:Callable):
    #     """
    #     è£…é¥°å™¨æ ¸å¿ƒé€»è¾‘
    #     ä½¿ç”¨æ–¹å¼: 
    #     @agent.tool
    #     def my_func(...): ...
    #     """
    #     # 1. ã€ç¿»è¯‘ã€‘è§£æžå‡½æ•°çš„ Schema (ç»™ LLM çœ‹çš„èœå•)
    #     schema = function_to_schema(func)
    #     self.tool_schemas.append(schema)
        
    #     # 2. ã€å…¥åº“ã€‘ä¿å­˜å‡½æ•°çš„å¯æ‰§è¡Œå¯¹è±¡ (ç»™ Agent æ‰§è¡Œç”¨çš„å·¥å…·ç®±)
    #     # ä½¿ç”¨å‡½æ•°åä½œä¸º Key
    #     self.tool_map[func.__name__] = func
        
    #     # 3. ã€å½’è¿˜ã€‘å¿…é¡»è¿”å›žåŽŸå‡½æ•°ï¼Œå¦åˆ™ Python ä»£ç é‡Œå°±æ²¡æ³•æ­£å¸¸è°ƒç”¨è¿™ä¸ªå‡½æ•°äº†
    #     return func
    

    # _execute_tool æ–¹æ³•ä¿æŒä¸å˜...
    def _execute_tool(self,tool_call:ChatCompletionMessageFunctionToolCall)->dict:
        #print("tool_call: " )
        #print(tool_call)
        fun = self.toolregistry.get_tool(tool_call.function.name)
        func_args = json.loads(tool_call.function.arguments)
        result = fun(**func_args)
        #print("result=" + str(result))
        tool_result = dict()
        tool_result["tool_call_id"] = tool_call.id
        tool_result["content"] = str(result)
        tool_result["role"] = "tool"
        tool_result["name"] = tool_call.function.name

        return  tool_result



    def run(self, prompt: str, max_turns: int = 5):
        # 1. å°†ç”¨æˆ·è¾“å…¥å­˜å…¥è®°å¿†
        self.memory.add(UserMessage(prompt))
        
        current_turn = 0
        while current_turn < max_turns:
            current_turn += 1
            
            # 2. ä»Ž Memory èŽ·å–æ•´ç†å¥½çš„æ¶ˆæ¯åˆ—è¡¨ï¼ˆå·²è‡ªåŠ¨å¤„ç†æ»‘åŠ¨çª—å£ï¼‰
            messages_to_send = self.memory.to_messages()
            #print("messages_to_send:")
            #print(messages_to_send)
            #print("self.toolregistry.tool_schemas:" )
            #print(self.toolregistry.tool_schemas)
            # 3. è°ƒç”¨ LLM
            # æ³¨æ„ï¼šä½ çš„ LLM ç±»çŽ°åœ¨è¿”å›žçš„æ˜¯ LLMMessage æˆ– ChatCompletionMessage
            response_message = self.llm.chat(messages_to_send, tools=self.toolregistry.tool_schemas)
            #print("response_message:")
           # print(response_message)
            # 4. å°† AI çš„å›žå¤å­˜å…¥è®°å¿†
            # å¦‚æžœ response_message æ˜¯ OpenAI åŽŸç”Ÿå¯¹è±¡ï¼Œéœ€è¦é€‚é…ä¸€ä¸‹å­˜å…¥ Memory
            # å‡è®¾ä½ çš„ LLM.chat å·²ç»æŒ‰ç…§åˆšæ‰çš„å»ºè®®ï¼Œè¿”å›žäº†åŒ…å« tool_calls çš„å¯¹è±¡
            
            # è¿™é‡Œçš„ response_message å¯èƒ½æ˜¯ OpenAI çš„åŽŸç”Ÿå¯¹è±¡ï¼Œæˆ‘ä»¬éœ€è¦æŠŠå®ƒå­˜è¿› Memory
            # ä¸ºäº†ç®€å•ï¼Œç›´æŽ¥å­˜å…¥ï¼ˆå› ä¸ºæˆ‘ä»¬ Memory å­˜çš„æ˜¯ Message å¯¹è±¡ï¼Œå¦‚æžœæ˜¯åŽŸç”Ÿå¯¹è±¡å¯èƒ½éœ€è¦è½¬æ¢ï¼Œ
            # ä½†ä¸ºäº†å…¼å®¹ä½ ä¹‹å‰çš„ LLMMessageï¼Œè¿™é‡Œå‡è®¾ LLM è¿”å›žçš„æ˜¯ LLMMessageï¼‰
            
            # ã€é‡è¦ã€‘å°† LLM çš„å›žå¤åŠ å…¥ Memory
            #temp = LLMMessage(content = response_message.content,
              #              tool_calls=str(response_message.tool_calls))
            #print("temp:" + str(temp))
            #self.memory.add(temp)
            #self.memory.add(response_message)

            # 5. åˆ¤æ–­æ˜¯å¦è°ƒç”¨å·¥å…·
            if response_message.tool_calls:
                temp = LLMMessage(content = response_message.content,
                          tool_calls=response_message.tool_calls)
                self.memory.add(temp)
                for tool_call in response_message.tool_calls:
                    self.memory.add(LLMMessage)
                    # æ‰§è¡Œå·¥å…·
                    tool_result_dict = self._execute_tool(tool_call)
                    #print("tool_result_dict:")
                    #print(tool_result_dict)
                    # å°è£…ä¸º ToolMessage å¯¹è±¡
                    tool_msg = ToolMessage(
                        content=tool_result_dict["content"],
                        tool_call_id=tool_result_dict["tool_call_id"]
                    )
                    #print("tool_msg:" + str(tool_msg))
                    
                    # å°†å·¥å…·ç»“æžœå­˜å…¥è®°å¿†
                    self.memory.add(tool_msg)
                
                # å¾ªçŽ¯ç»§ç»­ï¼Œä¸‹ä¸€è½® LLM ä¼šçœ‹åˆ°å·¥å…·ç»“æžœ
            else:
                temp = LLMMessage(content = response_message.content)
                self.memory.add(temp)
                print(f"ðŸ¤– Answer: {response_message.content}")
                return response_message.content
        
        return "Max turns reached."