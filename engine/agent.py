# éœ€è¦å¯¼å…¥æ–°çš„ Memory å’Œ Message ç±»
from core.memory import Memory
from core.message import UserMessage, SystemMessage, ToolMessage
from engine.tool import function_to_schema ,ToolRegistry
from openai.types.chat import ChatCompletionMessageFunctionToolCall
from openai.types.chat import ChatCompletionMessageToolCall
# ... å…¶ä»–åŸæœ‰å¯¼å…¥

'''
agent ç±»çš„ç»„æˆ
ä½¿ç”¨çš„LLMæ¨¡å‹ï¼š
å…¨éƒ¨çš„å·¥å…·å‡½æ•°ï¼š
memoryæ¨¡å—ï¼š



'''
class Agent:
    def __init__(self, llm, system_prompt: str = "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„ AI åŠ©æ‰‹ã€‚"):
        self.llm = llm
        #åˆå§‹åŒ–å·¥å…·æ¨¡å—
        self.toolregistry = ToolRegistry()
        # åˆå§‹åŒ–è®°å¿†æ¨¡å—
        self.memory = Memory(
            system_message=SystemMessage(system_prompt),
            max_messages=15 # è®¾å®šä¸€ä¸ªåˆç†çš„çª—å£å€¼
        )

        #

    # # tool è£…é¥°å™¨ä¿æŒä¸å˜...
    # def tool(self,func:Callable):
    #     """
    #     è£…é¥°å™¨æ ¸å¿ƒé€»è¾‘
    #     ä½¿ç”¨æ–¹å¼: 
    #     @agent.tool
    #     def my_func(...): ...
    #     """
    #     # 1. ã€ç¿»è¯‘ã€‘è§£æå‡½æ•°çš„ Schema (ç»™ LLM çœ‹çš„èœå•)
    #     schema = function_to_schema(func)
    #     self.tool_schemas.append(schema)
        
    #     # 2. ã€å…¥åº“ã€‘ä¿å­˜å‡½æ•°çš„å¯æ‰§è¡Œå¯¹è±¡ (ç»™ Agent æ‰§è¡Œç”¨çš„å·¥å…·ç®±)
    #     # ä½¿ç”¨å‡½æ•°åä½œä¸º Key
    #     self.tool_map[func.__name__] = func
        
    #     # 3. ã€å½’è¿˜ã€‘å¿…é¡»è¿”å›åŸå‡½æ•°ï¼Œå¦åˆ™ Python ä»£ç é‡Œå°±æ²¡æ³•æ­£å¸¸è°ƒç”¨è¿™ä¸ªå‡½æ•°äº†
    #     return func
    

    # _execute_tool æ–¹æ³•ä¿æŒä¸å˜...
    def _execute_tool(self,tool_call:ChatCompletionMessageFunctionToolCall):
        fun = self.toolregistry.get_tool(tool_call.function.name)



    def run(self, prompt: str, max_turns: int = 5):
        # 1. å°†ç”¨æˆ·è¾“å…¥å­˜å…¥è®°å¿†
        self.memory.add(UserMessage(prompt))
        
        current_turn = 0
        while current_turn < max_turns:
            current_turn += 1
            
            # 2. ä» Memory è·å–æ•´ç†å¥½çš„æ¶ˆæ¯åˆ—è¡¨ï¼ˆå·²è‡ªåŠ¨å¤„ç†æ»‘åŠ¨çª—å£ï¼‰
            messages_to_send = self.memory.to_messages()
            print(messages_to_send)
            print(self.toolregistry.tool_schemas)
            # 3. è°ƒç”¨ LLM
            # æ³¨æ„ï¼šä½ çš„ LLM ç±»ç°åœ¨è¿”å›çš„æ˜¯ LLMMessage æˆ– ChatCompletionMessage
            response_message = self.llm.chat(messages_to_send, tools=self.toolregistry.tool_schemas)
            
            print(response_message)
            # 4. å°† AI çš„å›å¤å­˜å…¥è®°å¿†
            # å¦‚æœ response_message æ˜¯ OpenAI åŸç”Ÿå¯¹è±¡ï¼Œéœ€è¦é€‚é…ä¸€ä¸‹å­˜å…¥ Memory
            # å‡è®¾ä½ çš„ LLM.chat å·²ç»æŒ‰ç…§åˆšæ‰çš„å»ºè®®ï¼Œè¿”å›äº†åŒ…å« tool_calls çš„å¯¹è±¡
            
            # è¿™é‡Œçš„ response_message å¯èƒ½æ˜¯ OpenAI çš„åŸç”Ÿå¯¹è±¡ï¼Œæˆ‘ä»¬éœ€è¦æŠŠå®ƒå­˜è¿› Memory
            # ä¸ºäº†ç®€å•ï¼Œç›´æ¥å­˜å…¥ï¼ˆå› ä¸ºæˆ‘ä»¬ Memory å­˜çš„æ˜¯ Message å¯¹è±¡ï¼Œå¦‚æœæ˜¯åŸç”Ÿå¯¹è±¡å¯èƒ½éœ€è¦è½¬æ¢ï¼Œ
            # ä½†ä¸ºäº†å…¼å®¹ä½ ä¹‹å‰çš„ LLMMessageï¼Œè¿™é‡Œå‡è®¾ LLM è¿”å›çš„æ˜¯ LLMMessageï¼‰
            
            # ã€é‡è¦ã€‘å°† LLM çš„å›å¤åŠ å…¥ Memory
            self.memory.add(response_message)

            # 5. åˆ¤æ–­æ˜¯å¦è°ƒç”¨å·¥å…·
            if response_message.tool_calls:
                for tool_call in response_message.tool_calls:
                    # æ‰§è¡Œå·¥å…·
                    tool_result_dict = self._execute_tool(tool_call)
                    
                    # å°è£…ä¸º ToolMessage å¯¹è±¡
                    tool_msg = ToolMessage(
                        content=tool_result_dict["content"],
                        tool_call_id=tool_result_dict["tool_call_id"]
                    )
                    
                    # å°†å·¥å…·ç»“æœå­˜å…¥è®°å¿†
                    self.memory.add(tool_msg)
                
                # å¾ªç¯ç»§ç»­ï¼Œä¸‹ä¸€è½® LLM ä¼šçœ‹åˆ°å·¥å…·ç»“æœ
            else:
                print(f"ğŸ¤– Answer: {response_message.content}")
                return response_message.content
        
        return "Max turns reached."